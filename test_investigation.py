import asyncio
import logging
import httpx

# Configurar el logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def generate_research_plan(prompt: str, model: str = "llama3:8b") -> list[str]:
    """Genera un plan de investigaci√≥n paso a paso basado en un prompt de usuario utilizando Ollama.

    Args:
        prompt (str): El tema o pregunta que el usuario quiere investigar.
        model (str): Modelo de Ollama a utilizar (por defecto "llama3.2:1b").

    Returns:
        list[str]: Lista de pasos a seguir en la investigaci√≥n.
    """
    logger.info("Generando plan de investigaci√≥n con Ollama...")

    try:
        # Prompt de sistema para estructurar la respuesta en pasos concretos
        system_prompt = (
            "Eres un asistente de investigaci√≥n experto en estructurar planes de estudio."
            "Tu tarea es generar un plan de investigaci√≥n claro y organizado para el siguiente tema.\n\n"
            "**Instrucciones:**\n"
            "- El plan debe tener **entre 1 y 5 pasos**, nunca m√°s.\n"
            "- Cada paso debe ser claro, breve y espec√≠fico.\n"
            "- Utiliza una lista numerada.\n\n"
            "**Ejemplo de formato:**\n"
            "1. Buscar la definici√≥n y conceptos b√°sicos.\n"
            "2. Investigar casos de uso en distintas fuentes.\n"
            "3. Analizar art√≠culos acad√©micos y estudios relevantes.\n"
            "4. Comparar diferentes perspectivas y teor√≠as.\n"
            "5. Resumir los hallazgos principales y elaborar conclusiones.\n\n"
            f"**Tema a investigar:** {prompt}\n\n"
            "Por favor, genera el plan de investigaci√≥n con entre **1 y 5 pasos**."
        )

        # Hacer la solicitud a la API de Ollama
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://localhost:11434/api/generate",  # URL del servidor Ollama
                json={"model": model, "prompt": system_prompt, "stream": False},
                timeout=60
            )

        # Verificar si la respuesta es v√°lida
        if response.status_code != 200:
            logger.error(f"Error en la respuesta de Ollama: {response.text}")
            return ["Error al generar el plan. Verifique que Ollama est√© en ejecuci√≥n."]

        # Extraer el contenido de la respuesta
        content = response.json().get("response", "")
        if not content:
            return ["No se pudo generar un plan de investigaci√≥n v√°lido."]

        # Extraer pasos numerados del contenido generado
        steps = [
            line.strip().lstrip("1234567890-. ")
            for line in content.split("\n")
            if line.strip() and (
                line.strip()[0].isdigit() or 
                line.strip().startswith("-") or 
                line.strip().startswith("‚Ä¢")
            )
        ]

        # Si no se extrajeron pasos, usar un plan gen√©rico
        if not steps:
            logger.warning("No se pudieron extraer pasos del plan, usando plan por defecto")
            steps = [
                "Definir los conceptos clave del tema",
                "Buscar fuentes confiables en l√≠nea",
                "Leer art√≠culos acad√©micos y estudios de caso",
                "Comparar diferentes perspectivas sobre el tema",
                "Redactar un resumen con las conclusiones m√°s importantes"
            ]

        logger.info(f"Plan de investigaci√≥n generado con {len(steps)} pasos")
        return steps

    except Exception as e:
        logger.error(f"Error al generar el plan de investigaci√≥n: {str(e)}")
        return [
            "Definir los conceptos clave del tema",
            "Buscar fuentes confiables en l√≠nea",
            "Leer art√≠culos acad√©micos y estudios de caso",
            "Comparar diferentes perspectivas sobre el tema",
            "Redactar un resumen con las conclusiones m√°s importantes"
        ]

# Funci√≥n principal para ejecutar la investigaci√≥n
async def main():
    prompt_usuario = input("Ingrese el tema de investigaci√≥n: ")

    # Llamar a la funci√≥n para generar el plan
    plan = await generate_research_plan(prompt_usuario)

    # Mostrar el resultado
    print("\nüîç Plan de investigaci√≥n generado:")
    for i, step in enumerate(plan, 1):
        print(f"{i}. {step}")

# Ejecutar la funci√≥n principal
asyncio.run(main())
